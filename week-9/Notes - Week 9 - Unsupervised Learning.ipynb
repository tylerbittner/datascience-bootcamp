{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course: Unsupervised Learning in Python\n",
    "- [DataCamp course link](https://www.datacamp.com/courses/unsupervised-learning-in-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre-load modules used later\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1: Clustering for dataset exploration\n",
    "- [Slides](slides/ch1_slides.pdf)\n",
    "\n",
    "\n",
    "**Unsupervised** tasks find patterns in data *without* a specific prediction task in mind.\n",
    "\n",
    "**k-means**\n",
    "- [**`sklearn.cluster.KMeans`**](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)\n",
    "    - `fit()` -- determines specified number (k) of cluster centroids\n",
    "    - `predict()` -- finds nearest centroid for each new sample\n",
    "- (Not to be confused with KNN, which is a *supervised classification* technique)\n",
    "\n",
    "Model performance metrics:\n",
    "- **cross-tabulation** is used to cross-check predicted labels with ground truth labels (if they are available!!).\n",
    "    - With pandas: `pd.crosstab(df['predicted_labels'], df['actual_labels'])`\n",
    "- **inertia** - measures how spread out the clusters are (*lower* is better).  *Does not require pre-labeled data.*  Mathematically, it's the mean of distances of each sample from its centroid.\n",
    "    - `model.inertia_`\n",
    "    \n",
    "\n",
    "In k-means, feature variance = feature influence, therefore normalization is often needed:\n",
    "- [`sklearn.preprocessing.StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) -- Scales *all* values for a feature.\n",
    "- `sklearn.preprocessing.Normalizer` -- Scales each value *independently*.\n",
    "- `sklearn.preprocessing.MaxAbsScaler`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2: Visualization with hierarchical clustering and t-SNE\n",
    "- [Slides](slides/ch2_slides.pdf)\n",
    "\n",
    "\n",
    "### Hierarchical clustering\n",
    "- Groups closest clusters into further clusters\n",
    "- \"agglomerative\" and \"divisive\" methods\n",
    "- A **dendrogram** is a great viz for hierarchies.  We'll use SciPy for this:\n",
    "    - **`scipy.cluster.hierarchy.linkage`**\n",
    "    - **`scipy.cluster.hierarchy.dendrogram`**\n",
    "        - The y-axis height in the dendrogram corresponds to *cluster distance*\n",
    "    - **`scipy.cluster.hierarchy.fcluster()`** -- returns NumPy array of cluster labels \n",
    "    \n",
    "## t-SNE\n",
    "- \"t-distributed stochastic neighbor embedding\" - Maps samples from a higher dimension into a 2D (or 3D) space, for easier visual interpretation!\n",
    "- `sklearn.manifold.TSNE`\n",
    "    - Only has a `.fit_transform()` method (not separate ones)\n",
    "    - `learning_rate` param is relevant here (usually between 50-200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3: Decorrelating your data and dimension reduction\n",
    "- [Slides](slides/ch3_slides.pdf)\n",
    "\n",
    "# PCA\n",
    "\n",
    "[**`sklearn.decomposition.PCA`**](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\n",
    "\n",
    "\n",
    "Two steps in PCA process:\n",
    "1. **Decorrelation**\n",
    "    - Finds principle components/axes, re-aligns data with them, and shifts data samples to a mean of 0 (`model.mean_` attribute).\n",
    "    - `.fit()` learns the model, `transform()` applies it.\n",
    "    - Components are stored in `model.components_` attribute.\n",
    "    - Columns of transformed matrix are the *PCA features*.  PCA features are NOT linearly correlated like dataset features may be.\n",
    "    - The first principal component of the data is *the direction in which the data varies the most*\n",
    "1. **Dimension reduction**\n",
    "    - **intrinsic dimension** -- Number of features/dimensions needed to approximate a data set.  \n",
    "        - Truly informative PCA features are those with *significant variance*!\n",
    "        - As a correllary, *low variance* features are considered \"noise.\"\n",
    "        - Variances are stored in the `pca_model.explained_variance_` attribute.\n",
    "    - Optionally specify dimensions you want with `PCA(n_components=n)` \n",
    "\n",
    "\n",
    "Alternative implementation for sparse arrays such as **`scipy.sparse.csr_matrix`** (like used in tf-idf word count matrices):\n",
    "- [**`sklearn.decomposition.TruncatedSVD`**](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html) supports `csr_matrix` and behaves like `PCA`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4: Discovering interpretable features\n",
    "- [Slides](slides/ch4_slides.pdf)\n",
    "\n",
    "### NMF - Non-negative Matrix Factorization\n",
    "[**`sklearn.decomposition.NMF`**](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html)\n",
    "\n",
    "\n",
    "NMF models are *interpretable* (vs. PCA).  It achieves this by decomposing samples as sums of their parts.\n",
    "- For example, it expresses documents as \"topics\" and images as combinations of patterns.  These are the *components*.\n",
    "- NMF has principle components are just like with PCA.  You *must* however specify `n_components` when instantiating NMF.\n",
    "- Features are computed by training the model.\n",
    "- NMF can approximately reproduce the original samples by combining the components & features (the product of their matrices -- **M**atrix **F**actorization!).\n",
    "- Can only be applied to non-negative data samples.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwv4DTvGH0TgQwTsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f07f860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "# Display grayscale images from matrices using `plt.imshow()`\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "moon_bitmap = [[ 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "               [ 0., 0., 0., 0.7, 0.8, 0., 0., 0.],\n",
    "               [ 0., 0., 0.8, 0.8, 0.9, 1., 0., 0.],\n",
    "               [ 0., 0.7, 0.9, 0.9, 1., 1., 1., 0.],\n",
    "               [ 0., 0.8, 0.9, 1., 1., 1., 1., 0.],\n",
    "               [ 0., 0., 0.9, 1., 1., 1., 0., 0.],\n",
    "               [ 0., 0., 0., 0.9, 1., 0., 0., 0.],\n",
    "               [ 0., 0., 0., 0., 0., 0., 0., 0.]]\n",
    "\n",
    "plt.imshow(moon_bitmap, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Recommender systems using NMF\n",
    "\n",
    "- **Cosine similarity** -- A measure of how similar documents are irrespective of their size. Mathematically, it measures the cosine of the angle between two vectors projected in a multi-dimensional space. The cosine similarity is advantageous because even if the two similar documents are far apart by the Euclidean distance (due to the size of the document), chances are they may still be oriented closer together. The smaller the angle, higher the cosine similarity. ([Reference](https://www.machinelearningplus.com/nlp/cosine-similarity/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.machinelearningplus.com/wp-content/uploads/2018/10/soft-cosine.png\" width=\"600\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cosine similarity example\n",
    "Image(url=\"https://www.machinelearningplus.com/wp-content/uploads/2018/10/soft-cosine.png\", width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
